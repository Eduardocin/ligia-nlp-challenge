# üîç Ligia NLP Challenge

> Solu√ß√£o completa de classifica√ß√£o de not√≠cias (Real vs Fake) usando Machine Learning cl√°ssico e Deep Learning com otimiza√ß√£o de hiperpar√¢metros.

Nota: Esta estrutura de projeto foi inicialmente gerada usando o template `cookiecutter-datascience`. Mantivemos a organiza√ß√£o e conven√ß√µes do template para facilitar reprodutibilidade, testes e contribui√ß√£o.

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Template: cookiecutter-datascience](https://img.shields.io/badge/template-cookiecutter--datascience-orange.svg)](https://drivendata.github.io/cookiecutter-data-science/)

## üìã Descri√ß√£o

Este projeto implementa pipelines completos de NLP para classifica√ß√£o bin√°ria de not√≠cias, comparando abordagens cl√°ssicas (TF-IDF + ML tradicional) com t√©cnicas modernas. O projeto inclui an√°lise explorat√≥ria, pr√©-processamento avan√ßado, modelagem baseline, otimiza√ß√£o de hiperpar√¢metros e avalia√ß√£o comparativa de modelos.

## Estrutura do Projeto

```
‚îú‚îÄ‚îÄ LICENSE                  <- Licen√ßa do projeto
‚îú‚îÄ‚îÄ Makefile                 <- Comandos de conveni√™ncia
‚îú‚îÄ‚îÄ README.md                <- Documenta√ß√£o principal
‚îú‚îÄ‚îÄ environment.yml          <- Ambiente conda completo
‚îú‚îÄ‚îÄ pyproject.toml           <- Configura√ß√£o do projeto (black, ruff)
‚îú‚îÄ‚îÄ requirements.txt         <- Depend√™ncias com vers√µes fixadas
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  <- Dados originais imut√°veis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.csv
‚îÇ   ‚îú‚îÄ‚îÄ interim/              <- Dados intermedi√°rios
‚îÇ   ‚îî‚îÄ‚îÄ processed/            <- Artefatos para modelagem
‚îÇ       ‚îú‚îÄ‚îÄ train_clean.csv       <- Texto pr√©-processado (treino)
‚îÇ       ‚îú‚îÄ‚îÄ test_clean.csv        <- Texto pr√©-processado (teste)
‚îÇ       ‚îú‚îÄ‚îÄ X_train_tfidf.npz     <- Matriz TF-IDF (treino)
‚îÇ       ‚îú‚îÄ‚îÄ X_val_tfidf.npz       <- Matriz TF-IDF (valida√ß√£o)
‚îÇ       ‚îú‚îÄ‚îÄ X_test_tfidf.npz      <- Matriz TF-IDF (teste)
‚îÇ       ‚îú‚îÄ‚îÄ tfidf_vectorizer.joblib
‚îÇ       ‚îú‚îÄ‚îÄ y_train.csv / y_val.csv
‚îÇ       ‚îú‚îÄ‚îÄ train_indices.csv / val_indices.csv
‚îÇ       ‚îî‚îÄ‚îÄ submission_*.csv      <- Arquivos de submiss√£o gerados
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ mlclassico/           <- Modelos de ML cl√°ssico (scikit-learn / XGBoost)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ char-ngrams-baseline/  <- Baselines com Character N-grams
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_0_xgboost.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_1_extra_trees.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_2_random_forest.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_3_linearsvc.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_4_sgdclassifier.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optimized/             <- Modelos com hiperpar√¢metros otimizados
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ extratrees_optimized.joblib
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ linearsvc_optimized.joblib
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sgdclassifier_optimized.joblib
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metadata.json
‚îÇ   ‚îî‚îÄ‚îÄ deeplearning/         <- Modelos de Deep Learning (TinyBERT)
‚îÇ       ‚îî‚îÄ‚îÄ tinybert_checkpoints/  <- Checkpoints HuggingFace Trainer
‚îÇ
‚îú‚îÄ‚îÄ notebooks/               <- Jupyter notebooks (executar na ordem)
‚îÇ   ‚îú‚îÄ‚îÄ 1.0-data-exploration.ipynb         <- EDA completa
‚îÇ   ‚îú‚îÄ‚îÄ 2.0-preprocessing.ipynb            <- Pr√©-processamento e vetoriza√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ 3.0-baseline-models.ipynb          <- Baselines com 5 classificadores
‚îÇ   ‚îú‚îÄ‚îÄ 3.1-hyperparameter-optimization.ipynb <- Otimiza√ß√£o de hiperpar√¢metros
‚îÇ   ‚îú‚îÄ‚îÄ 4.0-predictions.ipynb              <- Gera√ß√£o de submiss√µes
‚îÇ   ‚îî‚îÄ‚îÄ 5.0-tinybert.ipynb                 <- Fine-tuning TinyBERT
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ baseline_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ baseline_results_char_ngrams.csv
‚îÇ   ‚îú‚îÄ‚îÄ optimized_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing_experiments_results.csv
‚îÇ   ‚îî‚îÄ‚îÄ figures/              <- Gr√°ficos e figuras gerados pelos notebooks
‚îÇ
‚îú‚îÄ‚îÄ references/              <- Refer√™ncias e materiais de apoio
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ __init__.py
```

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### Op√ß√£o 1: Conda (Recomendado - Reprodutibilidade Garantida)

```bash
# Clonar reposit√≥rio
git clone https://github.com/seu-usuario/ligia-nlp-challenge.git
cd ligia-nlp-challenge

# Criar ambiente conda com todas as depend√™ncias
conda env create -f environment.yml

# Ativar ambiente
conda activate ligia-nlp

# Verificar instala√ß√£o
python -c "import sklearn, xgboost, transformers; print('‚úÖ Ambiente configurado com sucesso!')"

# Iniciar Jupyter Lab
jupyter lab
```

**Para atualizar o ambiente existente:**
```bash
conda env update -f environment.yml --prune
```

## üóÇÔ∏è Notebooks ‚Äî Pipeline de An√°lise

Execute os notebooks **na ordem abaixo** para reproduzir o pipeline completo.

### 1. An√°lise Explorat√≥ria de Dados (EDA)
[notebooks/1.0-data-exploration.ipynb](notebooks/1.0-data-exploration.ipynb)
- Estat√≠sticas descritivas do dataset
- Distribui√ß√£o de classes (balanceamento)
- Wordclouds e n-gramas por classe
- Identifica√ß√£o de data leakage (coluna `subject`)
- An√°lise de comprimento textual e padr√µes temporais

### 2. Pr√©-processamento de Texto
[notebooks/2.0-preprocessing.ipynb](notebooks/2.0-preprocessing.ipynb)
- Limpeza de texto (URLs, HTML, caracteres especiais)
- Remo√ß√£o de duplicatas
- Experimentos com diferentes estrat√©gias de normaliza√ß√£o
- Vetoriza√ß√£o TF-IDF com Character N-grams (4-6)
- Exporta: `data/processed/train_clean.csv`, `X_train_tfidf.npz`, `tfidf_vectorizer.joblib`

### 3. Modelos Baseline
[notebooks/3.0-baseline-models.ipynb](notebooks/3.0-baseline-models.ipynb)
- 5 classificadores com 5-Fold Cross-Validation:
  - Random Forest, Extra Trees, Logistic Regression, LinearSVC, SGDClassifier
- Avalia√ß√£o: Accuracy, F1 Weighted, Matriz de Confus√£o
- An√°lise de erros e top-features (Character N-grams)
- Salva modelos em `models/mlclassico/char-ngrams-baseline/`

### 3.1. Otimiza√ß√£o de Hiperpar√¢metros
[notebooks/3.1-hyperparameter-optimization.ipynb](notebooks/3.1-hyperparameter-optimization.ipynb)
- `RandomizedSearchCV` para LinearSVC, SGDClassifier e ExtraTrees
- Compara√ß√£o antes/depois da otimiza√ß√£o
- Salva modelos em `models/mlclassico/optimized/`

### 4. Gera√ß√£o de Predi√ß√µes e Submiss√£o
[notebooks/4.0-predictions.ipynb](notebooks/4.0-predictions.ipynb)
- Carrega modelo XGBoost + vetorizador TF-IDF
- Gera arquivo de submiss√£o para Kaggle
- An√°lise de concord√¢ncia entre modelos (XGBoost vs ExtraTrees)
- Ensemble por vota√ß√£o (XGBoost + LinearSVC)

### 5. Fine-tuning TinyBERT
[notebooks/5.0-tinybert.ipynb](notebooks/5.0-tinybert.ipynb)
- Modelo: `huawei-noah/TinyBERT_General_4L_312D` (~14.5 M par√¢metros)
- Tokeniza√ß√£o WordPiece com `title [SEP] text`
- HuggingFace Trainer com cosine schedule, label smoothing e early stopping
- Checkpoints salvos em `models/deeplearning/tinybert_checkpoints/`
- Gera√ß√£o de submiss√£o em `data/processed/submission_tinybert.csv`
- > **Nota:** Projetado para rodar com GPU. Em CPU o treinamento √© muito lento.

---

## üöÄ Como Usar

### Reproduzir Pipeline Completo

```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/seu-usuario/ligia-nlp-challenge.git
cd ligia-nlp-challenge

# 2. Configurar ambiente (Conda ‚Äî recomendado)
conda env create -f environment.yml
conda activate ligia-nlp

# Alternativa: pip
pip install -r requirements.txt

# 3. Verificar instala√ß√£o
python -c "import sklearn, xgboost, transformers; print('Ambiente OK')"

# 4. Iniciar Jupyter Lab e executar notebooks na ordem
jupyter lab
```

**Ordem de execu√ß√£o obrigat√≥ria:**

| # | Notebook | Tempo estimado |
|---|----------|----------------|
| 1 | `1.0-data-exploration.ipynb` | ~5 min |
| 2 | `2.0-preprocessing.ipynb` | ~10 min |
| 3 | `3.0-baseline-models.ipynb` | ~15 min |
| 4 | `3.1-hyperparameter-optimization.ipynb` | ~45-60 min |
| 5 | `4.0-predictions.ipynb` | ~2 min |
| 6 | `5.0-tinybert.ipynb` | ~10 min (GPU) |

### Submeter no Kaggle

Ap√≥s executar o notebook `4.0-predictions.ipynb`, os arquivos de submiss√£o estar√£o em `data/processed/`:

```bash
# Submeter via Kaggle CLI
kaggle competitions submit -c <competition-name> \
  -f data/processed/submission_xgboost.csv \
  -m "XGBoost baseline - char ngrams"
```

### Usar Modelo Pr√©-treinado

```python
import joblib
import scipy.sparse

# Carregar vetorizador e modelo otimizado
tfidf = joblib.load('data/processed/tfidf_vectorizer.joblib')
model = joblib.load('models/mlclassico/char-ngrams-baseline/model_0_xgboost.joblib')

# Fazer predi√ß√µes
texts = ["Breaking: President signs new bill into law"]
X = tfidf.transform(texts)
predictions = model.predict(X)
print(f"Predi√ß√£o: {'Fake' if predictions[0] == 1 else 'Real'}")

# Modelo otimizado (LinearSVC)
model_opt = joblib.load('models/mlclassico/optimized/linearsvc_optimized.joblib')
```

## Ô∏è Principais Tecnologias

| Categoria | Bibliotecas |
|-----------|-------------|
| Dados | `pandas`, `numpy`, `scipy` |
| Visualiza√ß√£o | `matplotlib`, `seaborn`, `wordcloud` |
| NLP | `nltk` |
| ML Cl√°ssico | `scikit-learn`, `xgboost` |
| Deep Learning | `torch`, `transformers`, `datasets`, `accelerate` |
| Serializa√ß√£o | `joblib` |
| Ambiente | Jupyter Lab, conda |

## üìÇ Dados

- **Fonte:** Dataset de not√≠cias reais e falsas (Kaggle ‚Äî LIGIA NLP Challenge)
- **Treino:** `data/raw/train.csv` (~22.8k amostras)
- **Teste:** `data/raw/test.csv` (~5k amostras)
- **Colunas:** `id`, `title`, `text`, `subject`, `date`, `label` (0 = Real, 1 = Fake)
- **Balanceamento:** Leve desbalanceamento

> ‚ö†Ô∏è **Data Leakage:** A coluna `subject` √© um proxy perfeito do label e deve ser **descartada** na modelagem.

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa especificada no arquivo [LICENSE](LICENSE).

## üë§ Autor

**Eduardo** - [GitHub](https://github.com/seu-usuario)

---

‚≠ê Se este projeto foi √∫til, considere dar uma estrela!
