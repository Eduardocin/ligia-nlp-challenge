# üîç Ligia NLP Challenge

> Solu√ß√£o completa de classifica√ß√£o de not√≠cias (Real vs Fake) usando Machine Learning cl√°ssico e Deep Learning com otimiza√ß√£o de hiperpar√¢metros.

Nota: Esta estrutura de projeto foi inicialmente gerada usando o template `cookiecutter-datascience`. Mantivemos a organiza√ß√£o e conven√ß√µes do template para facilitar reprodutibilidade, testes e contribui√ß√£o.

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Template: cookiecutter-datascience](https://img.shields.io/badge/template-cookiecutter--datascience-orange.svg)](https://drivendata.github.io/cookiecutter-data-science/)

## üìã Descri√ß√£o

Este projeto implementa pipelines completos de NLP para classifica√ß√£o bin√°ria de not√≠cias, comparando abordagens cl√°ssicas (TF-IDF + ML tradicional) com t√©cnicas modernas. O projeto inclui an√°lise explorat√≥ria, pr√©-processamento avan√ßado, modelagem baseline, otimiza√ß√£o de hiperpar√¢metros e avalia√ß√£o comparativa de modelos.

## Estrutura do Projeto

```
‚îú‚îÄ‚îÄ LICENSE                  <- Licen√ßa do projeto
‚îú‚îÄ‚îÄ Makefile                 <- Comandos de conveni√™ncia
‚îú‚îÄ‚îÄ README.md                <- Documenta√ß√£o principal
‚îú‚îÄ‚îÄ environment.yml          <- Ambiente conda completo
‚îú‚îÄ‚îÄ pyproject.toml           <- Configura√ß√£o do projeto (black, ruff)
‚îú‚îÄ‚îÄ requirements.txt         <- Depend√™ncias com vers√µes fixadas
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  <- Dados originais imut√°veis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.csv
‚îÇ   ‚îú‚îÄ‚îÄ interim/              <- Dados intermedi√°rios
‚îÇ   ‚îî‚îÄ‚îÄ processed/            <- Artefatos para modelagem
‚îÇ       ‚îú‚îÄ‚îÄ submission_*.csv      <- Arquivos de submiss√£o gerados
‚îÇ       ‚îî‚îÄ‚îÄ char_ngrams/          <- Artefatos TF-IDF (Character N-grams)
‚îÇ           ‚îú‚îÄ‚îÄ train_clean.csv
‚îÇ           ‚îú‚îÄ‚îÄ test_clean.csv
‚îÇ           ‚îú‚îÄ‚îÄ X_train_tfidf.npz
‚îÇ           ‚îú‚îÄ‚îÄ X_val_tfidf.npz
‚îÇ           ‚îú‚îÄ‚îÄ X_test_tfidf.npz
‚îÇ           ‚îú‚îÄ‚îÄ tfidf_vectorizer_char_ngrams.joblib
‚îÇ           ‚îú‚îÄ‚îÄ y_train.csv / y_val.csv
‚îÇ           ‚îî‚îÄ‚îÄ train_indices.csv / val_indices.csv
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ mlclassico/           <- Modelos de ML cl√°ssico (scikit-learn / XGBoost)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ char-ngrams-baseline/  <- Baselines com Character N-grams
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_1_xgboost.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_2_extra_trees.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_3_random_forest.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_4_linearsvc.joblib
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_5_sgdclassifier.joblib
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optimized/             <- Modelos com hiperpar√¢metros otimizados
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ extratrees_optimized.joblib
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ linearsvc_optimized.joblib
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sgdclassifier_optimized.joblib
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metadata.json
‚îÇ   ‚îî‚îÄ‚îÄ deeplearning/         <- Modelo TinyBERT fine-tuned (HuggingFace format)
‚îÇ       ‚îú‚îÄ‚îÄ config.json
‚îÇ       ‚îú‚îÄ‚îÄ model.safetensors
‚îÇ       ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ       ‚îî‚îÄ‚îÄ tokenizer_config.json
‚îÇ
‚îú‚îÄ‚îÄ notebooks/               <- Jupyter notebooks (executar na ordem)
‚îÇ   ‚îú‚îÄ‚îÄ 1.0-data-exploration.ipynb         <- EDA completa
‚îÇ   ‚îú‚îÄ‚îÄ 2.0-preprocessing.ipynb            <- Pr√©-processamento e vetoriza√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ 3.0-baseline-models.ipynb          <- Baselines com 5 classificadores
‚îÇ   ‚îú‚îÄ‚îÄ 3.1-hyperparameter-optimization.ipynb <- Otimiza√ß√£o de hiperpar√¢metros
‚îÇ   ‚îú‚îÄ‚îÄ 4.0-predictions.ipynb              <- Gera√ß√£o de submiss√µes + LIME
‚îÇ   ‚îî‚îÄ‚îÄ 5.0-tinybert.ipynb                 <- Fine-tuning TinyBERT + LIME
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ baseline_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ baseline_results_char_ngrams.csv
‚îÇ   ‚îú‚îÄ‚îÄ optimized_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing_experiments_results.csv
‚îÇ   ‚îî‚îÄ‚îÄ figures/              <- Gr√°ficos e figuras gerados pelos notebooks
‚îÇ
‚îú‚îÄ‚îÄ references/              <- Refer√™ncias e materiais de apoio
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ __init__.py
```

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### Op√ß√£o 1: Conda (Recomendado - Reprodutibilidade Garantida)

```bash
# Clonar reposit√≥rio
git clone https://github.com/seu-usuario/ligia-nlp-challenge.git
cd ligia-nlp-challenge

# Criar ambiente conda com todas as depend√™ncias
conda env create -f environment.yml

# Ativar ambiente
conda activate ligia-nlp

# Verificar instala√ß√£o
python -c "import sklearn, xgboost, transformers; print('‚úÖ Ambiente configurado com sucesso!')"

# Iniciar Jupyter Lab
jupyter lab
```

**Para atualizar o ambiente existente:**
```bash
conda env update -f environment.yml --prune
```

## üóÇÔ∏è Notebooks ‚Äî Pipeline de An√°lise

Execute os notebooks **na ordem abaixo** para reproduzir o pipeline completo.

### 1. An√°lise Explorat√≥ria de Dados (EDA)
[notebooks/1.0-data-exploration.ipynb](notebooks/1.0-data-exploration.ipynb)
- Estat√≠sticas descritivas do dataset
- Distribui√ß√£o de classes (balanceamento)
- Wordclouds e n-gramas por classe
- Identifica√ß√£o de data leakage (coluna `subject`)
- An√°lise de comprimento textual e padr√µes temporais

### 2. Pr√©-processamento de Texto
[notebooks/2.0-preprocessing.ipynb](notebooks/2.0-preprocessing.ipynb)
- Limpeza de texto (URLs, HTML, caracteres especiais)
- Remo√ß√£o de duplicatas
- Experimentos com diferentes estrat√©gias de normaliza√ß√£o
- Vetoriza√ß√£o TF-IDF com Character N-grams (4-6)
- Exporta: `data/processed/train_clean.csv`, `X_train_tfidf.npz`, `tfidf_vectorizer.joblib`

### 3. Modelos Baseline
[notebooks/3.0-baseline-models.ipynb](notebooks/3.0-baseline-models.ipynb)
- 5 classificadores com 5-Fold Cross-Validation:
  - Random Forest, Extra Trees, Logistic Regression, LinearSVC, SGDClassifier
- Avalia√ß√£o: Accuracy, F1 Weighted, Matriz de Confus√£o
- An√°lise de erros e top-features (Character N-grams)
- Salva modelos em `models/mlclassico/char-ngrams-baseline/`

### 3.1. Otimiza√ß√£o de Hiperpar√¢metros
[notebooks/3.1-hyperparameter-optimization.ipynb](notebooks/3.1-hyperparameter-optimization.ipynb)
- `RandomizedSearchCV` para LinearSVC, SGDClassifier e ExtraTrees
- Compara√ß√£o antes/depois da otimiza√ß√£o
- Salva modelos em `models/mlclassico/optimized/`

### 4. Gera√ß√£o de Predi√ß√µes e Submiss√£o
[notebooks/4.0-predictions.ipynb](notebooks/4.0-predictions.ipynb)
- Carrega modelos XGBoost + LinearSVC (calibrado) + vetorizador TF-IDF
- Gera arquivos de submiss√£o para Kaggle: `submission_xgboost.csv`, `submission_linearsvc.csv`, `submission_ensemble_xgb_svc_svc_wins.csv`
- An√°lise de concord√¢ncia entre modelos
- Ensemble por vota√ß√£o suave (XGBoost + LinearSVC)
- **Se√ß√£o 8:** Interpretabilidade com LIME ‚Äî exemplos individuais, compara√ß√£o Real vs Fake e top palavras globais agregadas

### 5. Fine-tuning TinyBERT
[notebooks/5.0-tinybert.ipynb](notebooks/5.0-tinybert.ipynb)
- Modelo: `huawei-noah/TinyBERT_General_4L_312D` (~14.5 M par√¢metros)
- Tokeniza√ß√£o WordPiece com `title [SEP] text`
- HuggingFace Trainer com cosine schedule, label smoothing e early stopping
- Modelo salvo em `models/deeplearning/` (compat√≠vel com HuggingFace `from_pretrained`)
- Gera√ß√£o de submiss√£o em `data/processed/submission_tinybert.csv`
- **Se√ß√£o 10:** Interpretabilidade com LIME ‚Äî exemplos individuais, compara√ß√£o Real vs Fake e top palavras globais agregadas
- > **Nota:** GPU fortemente recomendada (T4/V100). Em CPU o treinamento √© muito lento.

---

## üöÄ Como Usar

### Reproduzir Pipeline Completo

```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/seu-usuario/ligia-nlp-challenge.git
cd ligia-nlp-challenge

# 2. Configurar ambiente (Conda ‚Äî recomendado)
conda env create -f environment.yml
conda activate ligia-nlp

# Alternativa: pip
pip install -r requirements.txt

# 3. Verificar instala√ß√£o
python -c "import sklearn, xgboost, transformers; print('Ambiente OK')"

# 4. Iniciar Jupyter Lab e executar notebooks na ordem
jupyter lab
```

**Ordem de execu√ß√£o obrigat√≥ria:**

| # | Notebook | Tempo estimado |
|---|----------|----------------|
| 1 | `1.0-data-exploration.ipynb` | ~5 min |
| 2 | `2.0-preprocessing.ipynb` | ~10 min |
| 3 | `3.0-baseline-models.ipynb` | ~15 min |
| 4 | `3.1-hyperparameter-optimization.ipynb` | ~45-60 min |
| 5 | `4.0-predictions.ipynb` | ~2 min |
| 6 | `5.0-tinybert.ipynb` | ~10 min (GPU) |

### Gerar e Submeter no Kaggle

#### Passo 1 ‚Äî Gerar o arquivo de submiss√£o

**ML Cl√°ssico (Ensemble XGBoost + LinearSVC):**
Execute o notebook `4.0-predictions.ipynb` at√© o final. O arquivo ser√° salvo automaticamente em:
```
data/processed/submission_ensemble_xgb_svc_svc_wins.csv
```

**Deep Learning (TinyBERT):**
Execute o notebook `5.0-tinybert.ipynb` at√© a se√ß√£o 9. O arquivo ser√° salvo em:
```
data/processed/submission_tinybert.csv
```

> ‚ö†Ô∏è O TinyBERT requer GPU. No Google Colab, ative em `Ambiente de execu√ß√£o ‚Üí Alterar tipo de execu√ß√£o ‚Üí T4 GPU`.

#### Passo 2 ‚Äî Instalar o Kaggle CLI (primeira vez)

```bash
pip install kaggle

# Configurar credenciais (baixar kaggle.json em kaggle.com ‚Üí Account ‚Üí API)
mkdir -p ~/.kaggle
cp kaggle.json ~/.kaggle/kaggle.json
chmod 600 ~/.kaggle/kaggle.json
```

No Windows (PowerShell):
```powershell
mkdir "$env:USERPROFILE\.kaggle" -Force
Copy-Item kaggle.json "$env:USERPROFILE\.kaggle\kaggle.json"
```

#### Passo 3 ‚Äî Submeter via CLI

```bash
# Ensemble XGBoost + LinearSVC
kaggle competitions submit -c ligia-nlp-challenge \
  -f data/processed/submission_ensemble_xgb_svc_svc_wins.csv \
  -m "Ensemble XGBoost + LinearSVC (char n-grams)"

# LinearSVC otimizado
kaggle competitions submit -c ligia-nlp-challenge \
  -f data/processed/submission_linearsvc.csv \
  -m "LinearSVC otimizado (char n-grams)"

# TinyBERT fine-tuned
kaggle competitions submit -c ligia-nlp-challenge \
  -f data/processed/submission_tinybert.csv \
  -m "TinyBERT fine-tuned (4L-312D)"
```

> Substitua `ligia-nlp-challenge` pelo nome exato da competi√ß√£o no Kaggle (vis√≠vel na URL da competi√ß√£o).

#### Alternativa ‚Äî Submeter pela interface web

1. Acesse a p√°gina da competi√ß√£o no Kaggle
2. Clique em **Submit Predictions**
3. Fa√ßa upload do arquivo `submission_*.csv` desejado
4. Adicione uma descri√ß√£o e confirme

### Usar Modelo Pr√©-treinado

```python
import joblib, scipy.sparse

# Carregar vetorizador (Character N-grams)
tfidf = joblib.load('data/processed/char_ngrams/tfidf_vectorizer_char_ngrams.joblib')

# Modelo baseline XGBoost
model = joblib.load('models/mlclassico/char-ngrams-baseline/model_1_xgboost.joblib')

# Fazer predi√ß√µes
texts = ["Breaking: President signs new bill into law"]
X = tfidf.transform(texts)
predictions = model.predict(X)
print(f"Predi√ß√£o: {'Fake' if predictions[0] == 1 else 'Real'}")

# Modelos otimizados dispon√≠veis
linearsvc = joblib.load('models/mlclassico/optimized/linearsvc_optimized.joblib')
extratrees = joblib.load('models/mlclassico/optimized/extratrees_optimized.joblib')
```

**TinyBERT (HuggingFace):**
```python
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained('models/deeplearning')
model = AutoModelForSequenceClassification.from_pretrained('models/deeplearning')
model.eval()

text = "Breaking: President signs new bill into law"
inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
with torch.no_grad():
    logits = model(**inputs).logits
pred = torch.argmax(logits, dim=-1).item()
print(f"Predi√ß√£o: {'Fake' if pred == 1 else 'Real'}")
```

## üìÇ Dados

- **Fonte:** Dataset de not√≠cias reais e falsas (Kaggle ‚Äî LIGIA NLP Challenge)
- **Treino:** `data/raw/train.csv` (~22.8k amostras)
- **Teste:** `data/raw/test.csv` (~5k amostras)
- **Colunas:** `id`, `title`, `text`, `subject`, `date`, `label` (0 = Real, 1 = Fake)
- **Balanceamento:** Leve desbalanceamento

> ‚ö†Ô∏è **Data Leakage:** A coluna `subject` √© um proxy perfeito do label e deve ser **descartada** na modelagem.

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa especificada no arquivo [LICENSE](LICENSE).

## üë§ Autor

**Eduardo** - [GitHub](https://github.com/seu-usuario)

---

‚≠ê Se este projeto foi √∫til, considere dar uma estrela!
