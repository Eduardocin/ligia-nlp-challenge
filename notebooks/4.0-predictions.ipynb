{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62082490",
   "metadata": {},
   "source": [
    "# ðŸ“¤ PrediÃ§Ãµes no Conjunto de Teste â€” SubmissÃ£o\n",
    "\n",
    "## Objetivo\n",
    "Gerar o arquivo de submissÃ£o para a competiÃ§Ã£o aplicando o **melhor modelo treinado** (`model_0_xgboost`) sobre o conjunto de teste prÃ©-processado.\n",
    "\n",
    "## Pipeline\n",
    "1. Carregar o vetorizador TF-IDF (Character N-grams) salvo no notebook 2.0\n",
    "2. Carregar o modelo `model_0_xgboost.joblib` do diretÃ³rio `char-ngrams-baseline`\n",
    "3. Carregar os dados de teste limpos (`test_clean.csv`)\n",
    "4. Vetorizar o texto de teste com o mesmo TF-IDF do treino\n",
    "5. Gerar prediÃ§Ãµes e salvar CSV no formato da competiÃ§Ã£o\n",
    "\n",
    "## Formato de saÃ­da\n",
    "```\n",
    "id,target\n",
    "5398,1\n",
    "5503,0\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f9c83",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fb920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "MODEL_DIR = '../models/char-ngrams-baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28315512",
   "metadata": {},
   "source": [
    "## 2. Carregar modelo e vetorizador TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691051c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Vetorizador carregado  â€” ../data/processed\\tfidf_vectorizer.joblib\n",
      "  vocab: 50,000 tokens | analyzer: char | ngram: (3, 5)\n",
      "\n",
      "âœ“ Modelo carregado       â€” ../models/char-ngrams-baseline\\model_0_xgboost.joblib\n",
      "  tipo: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "import os, joblib\n",
    "\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "\n",
    "vect_path  = os.path.join(PROCESSED_DIR, 'tfidf_vectorizer.joblib')\n",
    "model_path = os.path.join(MODEL_DIR, 'model_0_xgboost.joblib')\n",
    "\n",
    "assert os.path.exists(vect_path),  f\"Vetorizador nÃ£o encontrado: {vect_path}\"\n",
    "assert os.path.exists(model_path), f\"Modelo nÃ£o encontrado: {model_path}\"\n",
    "\n",
    "vectorizer = joblib.load(vect_path)\n",
    "model      = joblib.load(model_path)\n",
    "\n",
    "print(f\"âœ“ Vetorizador carregado  â€” {vect_path}\")\n",
    "print(f\"  vocab: {len(vectorizer.vocabulary_):,} tokens | analyzer: {vectorizer.analyzer} | ngram: {vectorizer.ngram_range}\")\n",
    "print(f\"\\nâœ“ Modelo carregado       â€” {model_path}\")\n",
    "print(f\"  tipo: {type(model).__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a772015",
   "metadata": {},
   "source": [
    "## 3. Carregar dados de teste\n",
    "\n",
    "- **IDs** vÃªm do `test.csv` (raw)\n",
    "- **Texto limpo** vem do `test_clean.csv` (prÃ©-processado no notebook 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fc1293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras de teste: 5,712\n"
     ]
    }
   ],
   "source": [
    "# IDs do arquivo raw\n",
    "df_raw = pd.read_csv('../data/raw/test.csv')\n",
    "ids = df_raw['id'].values\n",
    "\n",
    "# Texto limpo do prÃ©-processamento\n",
    "df_clean = pd.read_csv('../data/processed/test_clean.csv')\n",
    "\n",
    "# Preencher nulos e combinar title + text (mesmo pipeline do treino)\n",
    "df_clean['title'] = df_clean['title'].fillna('')\n",
    "df_clean['text'] = df_clean['text'].fillna('')\n",
    "df_clean['full_text'] = df_clean['title'] + ' ' + df_clean['text']\n",
    "\n",
    "assert len(ids) == len(df_clean), f\"Mismatch: {len(ids)} IDs vs {len(df_clean)} textos\"\n",
    "\n",
    "print(f\"Amostras de teste: {len(df_clean):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bc53c",
   "metadata": {},
   "source": [
    "## 4. Vetorizar e gerar prediÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55342386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vetorizando conjunto de teste...\n",
      "âœ“ VetorizaÃ§Ã£o concluÃ­da em 20.2s\n",
      "  Shape: 5,712 docs Ã— 50,000 features\n",
      "\n",
      "Gerando prediÃ§Ãµes com XGBoost...\n",
      "âœ“ PrediÃ§Ãµes geradas em 0.2s\n",
      "\n",
      "DistribuiÃ§Ã£o das prediÃ§Ãµes:\n",
      "  Classe 0 (Real): 4,281 (74.9%)\n",
      "  Classe 1 (Fake): 1,431 (25.1%)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Vetorizando conjunto de teste...\")\n",
    "t0 = time.time()\n",
    "X_test = vectorizer.transform(df_clean['full_text'])\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"âœ“ VetorizaÃ§Ã£o concluÃ­da em {elapsed:.1f}s\")\n",
    "print(f\"  Shape: {X_test.shape[0]:,} docs Ã— {X_test.shape[1]:,} features\")\n",
    "\n",
    "print(\"\\nGerando prediÃ§Ãµes com XGBoost...\")\n",
    "t0 = time.time()\n",
    "preds = model.predict(X_test)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"âœ“ PrediÃ§Ãµes geradas em {elapsed:.1f}s\")\n",
    "print(f\"\\nDistribuiÃ§Ã£o das prediÃ§Ãµes:\")\n",
    "unique, counts = np.unique(preds, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    label = 'Fake' if cls == 1 else 'Real'\n",
    "    print(f\"  Classe {int(cls)} ({label}): {cnt:,} ({cnt / len(preds):.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b502d",
   "metadata": {},
   "source": [
    "## 5. Salvar CSV de submissÃ£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82504272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SubmissÃ£o salva em: ../data/processed/submission_xgboost.csv\n",
      "  Linhas: 5,712\n",
      "\n",
      "Primeiras 10 linhas:\n",
      "   id  target\n",
      " 5398       1\n",
      " 5503       1\n",
      "23151       0\n",
      "12669       0\n",
      "27864       0\n",
      "23035       0\n",
      "25746       0\n",
      "27194       0\n",
      "  933       1\n",
      "11610       0\n"
     ]
    }
   ],
   "source": [
    "SUBMISSION_PATH = '../data/processed/submission_xgboost.csv'\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id':     ids,\n",
    "    'target': preds.astype(int),\n",
    "})\n",
    "\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "print(f\"âœ“ SubmissÃ£o salva em: {SUBMISSION_PATH}\")\n",
    "print(f\"  Linhas: {len(submission):,}\")\n",
    "print(f\"\\nPrimeiras 10 linhas:\")\n",
    "print(submission.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cac90f",
   "metadata": {},
   "source": [
    "## 6. ValidaÃ§Ã£o do formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a28ebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VALIDAÃ‡ÃƒO DO ARQUIVO DE SUBMISSÃƒO\n",
      "==================================================\n",
      "  âœ“  Colunas corretas (id, target)\n",
      "  âœ“  Sem valores nulos\n",
      "  âœ“  Apenas classes 0 e 1\n",
      "  âœ“  IDs Ãºnicos\n",
      "  âœ“  NÂº de linhas = 5,712\n",
      "\n",
      "âœ… Arquivo vÃ¡lido para submissÃ£o!\n",
      "   Arquivo : ../data/processed/submission_xgboost.csv\n",
      "   Modelo  : model_0_xgboost  (XGBClassifier)\n",
      "   Amostras: 5,712\n"
     ]
    }
   ],
   "source": [
    "df_sub = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "checks = {\n",
    "    'Colunas corretas (id, target)'  : list(df_sub.columns) == ['id', 'target'],\n",
    "    'Sem valores nulos'              : df_sub.isnull().sum().sum() == 0,\n",
    "    'Apenas classes 0 e 1'          : set(df_sub['target'].unique()).issubset({0, 1}),\n",
    "    'IDs Ãºnicos'                     : df_sub['id'].nunique() == len(df_sub),\n",
    "    f'NÂº de linhas = {len(ids):,}'   : len(df_sub) == len(ids),\n",
    "}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"VALIDAÃ‡ÃƒO DO ARQUIVO DE SUBMISSÃƒO\")\n",
    "print(\"=\" * 50)\n",
    "all_ok = True\n",
    "for check, result in checks.items():\n",
    "    status = 'âœ“' if result else 'âœ— FALHOU'\n",
    "    if not result:\n",
    "        all_ok = False\n",
    "    print(f\"  {status}  {check}\")\n",
    "\n",
    "print()\n",
    "if all_ok:\n",
    "    print(\"âœ… Arquivo vÃ¡lido para submissÃ£o!\")\n",
    "    print(f\"   Arquivo : {SUBMISSION_PATH}\")\n",
    "    print(f\"   Modelo  : model_0_xgboost  ({type(model).__name__})\")\n",
    "    print(f\"   Amostras: {len(df_sub):,}\")\n",
    "else:\n",
    "    print(\"âŒ Corrija os erros antes de submeter.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9cbaa",
   "metadata": {},
   "source": [
    "## 7. ComparaÃ§Ã£o de SubmissÃµes â€” ExtraTrees vs XGBoost\n",
    "\n",
    "Como ambos os modelos obtiveram o **mesmo score** na competiÃ§Ã£o, analisamos:\n",
    "- Taxa de concordÃ¢ncia entre as prediÃ§Ãµes\n",
    "- Exemplos de **discordÃ¢ncias** (onde um modelo acerta e o outro pode errar)\n",
    "- **Ensemble por votaÃ§Ã£o majoritÃ¡ria** (ambos concordam -> usa a prediÃ§Ã£o; discordam -> define regra de desempate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a4fef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARAÃ‡ÃƒO: ExtraTrees vs XGBoost\n",
      "============================================================\n",
      "  Total de amostras  : 5,712\n",
      "  Concordam          : 5,710  (99.96%)\n",
      "  Discordam          : 2  (0.04%)\n",
      "\n",
      "  DiscordÃ¢ncias por padrÃ£o:\n",
      "    ET=Fake / XGB=Real : 1\n",
      "    ET=Real / XGB=Fake : 1\n",
      "\n",
      "  Primeiras 10 discordÃ¢ncias:\n",
      "   id  extratrees  xgboost\n",
      "22809           1        0\n",
      "16447           0        1\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Classe         ExtraTrees      XGBoost\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Real (0)         4,281 (74.9%)      4,281 (74.9%)\n",
      "Fake (1)         1,431 (25.1%)      1,431 (25.1%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# â”€â”€ Carregar as duas submissÃµes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sub_et  = pd.read_csv('../data/processed/submission_extratrees.csv').rename(columns={'target': 'extratrees'})\n",
    "sub_xgb = pd.read_csv('../data/processed/submission_xgboost.csv').rename(columns={'target': 'xgboost'})\n",
    "\n",
    "df_cmp = sub_et.merge(sub_xgb, on='id')\n",
    "\n",
    "# â”€â”€ ConcordÃ¢ncia global â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "agree_mask  = df_cmp['extratrees'] == df_cmp['xgboost']\n",
    "n_total     = len(df_cmp)\n",
    "n_agree     = agree_mask.sum()\n",
    "n_disagree  = n_total - n_agree\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARAÃ‡ÃƒO: ExtraTrees vs XGBoost\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Total de amostras  : {n_total:,}\")\n",
    "print(f\"  Concordam          : {n_agree:,}  ({n_agree/n_total:.2%})\")\n",
    "print(f\"  Discordam          : {n_disagree:,}  ({n_disagree/n_total:.2%})\")\n",
    "\n",
    "# â”€â”€ Detalhamento das discordÃ¢ncias â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_disagree = df_cmp[~agree_mask].copy()\n",
    "if n_disagree > 0:\n",
    "    et1_xgb0 = ((df_disagree['extratrees'] == 1) & (df_disagree['xgboost'] == 0)).sum()\n",
    "    et0_xgb1 = ((df_disagree['extratrees'] == 0) & (df_disagree['xgboost'] == 1)).sum()\n",
    "    print(f\"\\n  DiscordÃ¢ncias por padrÃ£o:\")\n",
    "    print(f\"    ET=Fake / XGB=Real : {et1_xgb0:,}\")\n",
    "    print(f\"    ET=Real / XGB=Fake : {et0_xgb1:,}\")\n",
    "\n",
    "    print(f\"\\n  Primeiras 10 discordÃ¢ncias:\")\n",
    "    print(df_disagree.head(10).to_string(index=False))\n",
    "\n",
    "# â”€â”€ DistribuiÃ§Ã£o das prediÃ§Ãµes por modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\n{'â”€'*60}\")\n",
    "print(f\"{'Classe':<12} {'ExtraTrees':>12} {'XGBoost':>12}\")\n",
    "print(f\"{'â”€'*60}\")\n",
    "for cls in [0, 1]:\n",
    "    label = 'Real (0)' if cls == 0 else 'Fake (1)'\n",
    "    n_et  = (df_cmp['extratrees'] == cls).sum()\n",
    "    n_xgb = (df_cmp['xgboost']   == cls).sum()\n",
    "    print(f\"{label:<12} {n_et:>9,} ({n_et/n_total:.1%})  {n_xgb:>9,} ({n_xgb/n_total:.1%})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ligia-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
